{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_column',999)\n",
    "pd.set_option('display.max_row',999)\n",
    "\n",
    "chemin = 'D:/Documents/OpenClassrooms/P7_delfosse_emilie/P7_prediction/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_strat=pd.read_csv(chemin+'/prepared_data.csv',index_col=0)\n",
    "\n",
    "y_train_strat=X_train_strat['TARGET']\n",
    "X_train_strat.drop(columns=['TARGET'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30751, 788)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_strat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=(y_train_strat.value_counts()/y_train_strat.shape[0]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "clfs = {\n",
    "#     'KNN':KNeighborsClassifier(),\n",
    "#     'gb': GradientBoostingClassifier(random_state = 40),\n",
    "#     'dt': DecisionTreeClassifier(random_state = 40),\n",
    "#     'rf': RandomForestClassifier(random_state=40),\n",
    "#     'mlp': MLPClassifier(random_state=40),\n",
    "#     'ada': AdaBoostClassifier(random_state = 40),\n",
    "#     'gnb':GaussianNB(),\n",
    "    'xgboost' : XGBClassifier(random_state = 40,class_weight=weight),\n",
    "    'lightgbm ' : LGBMClassifier(random_state = 40,class_weight=weight),\n",
    "    'l2':LogisticRegression(random_state = 40,class_weight=weight),\n",
    "    'l1':LogisticRegression(penalty='l1',solver='saga',random_state = 40,class_weight=weight)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold    \n",
    "def test_model(rf,X_train,y_train):\n",
    "    cv = StratifiedKFold(n_splits= 10, shuffle=True, random_state=45)\n",
    "    p = cross_val_score(rf, X_train.values, y_train.values, cv=cv, scoring=make_scorer(precision_score,average='weighted'))           \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:45:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:45:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:45:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:47:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:47:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "___\n",
      "lightgbm \n",
      "___\n",
      "l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>l2</th>\n",
       "      <th>l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.854878</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.844654</td>\n",
       "      <td>0.844654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.845035</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>0.845204</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863508</td>\n",
       "      <td>0.845107</td>\n",
       "      <td>0.845155</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.858800</td>\n",
       "      <td>0.845010</td>\n",
       "      <td>0.845204</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.855391</td>\n",
       "      <td>0.858800</td>\n",
       "      <td>0.845204</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.845131</td>\n",
       "      <td>0.845131</td>\n",
       "      <td>0.845131</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.845059</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.865569</td>\n",
       "      <td>0.845083</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.865255</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.844606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.852760</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.844606</td>\n",
       "      <td>0.844606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    xgboost  lightgbm         l2        l1\n",
       "0  0.854878   0.844509  0.844654  0.844654\n",
       "1  0.845035   0.865569  0.845204  0.845204\n",
       "2  0.863508   0.845107  0.845155  0.845204\n",
       "3  0.858800   0.845010  0.845204  0.845204\n",
       "4  0.855391   0.858800  0.845204  0.845204\n",
       "5  0.845131   0.845131  0.845131  0.845204\n",
       "6  0.845059   0.865772  0.845180  0.845204\n",
       "7  0.865569   0.845083  0.845180  0.845204\n",
       "8  0.865255   0.844509  0.844509  0.844606\n",
       "9  0.852760   0.844509  0.844606  0.844606"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p={}\n",
    "for i in clfs:\n",
    "    print(i)\n",
    "    p[i] = test_model(clfs[i],X_train_strat,y_train_strat)\n",
    "    print('___')\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>rank_mean</th>\n",
       "      <th>rank_max</th>\n",
       "      <th>final_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.855139</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean       max  rank_mean  rank_max  final_rank\n",
       "xgboost  0.855139  0.865569        1.0       2.0         3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_p=p.mean()\n",
    "max_p=p.max()\n",
    "\n",
    "result_p=pd.concat([mean_p,max_p],keys=['mean','max'],axis=1)\n",
    "result_p['rank_mean']=result_p['mean'].rank(ascending=False)\n",
    "result_p['rank_max']=result_p['max'].rank(ascending=False)\n",
    "\n",
    "result_p['final_rank']=(result_p['rank_max']+result_p['rank_mean'])\n",
    "\n",
    "result_p.sort_values(by='final_rank').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(1, 1,figsize=(10,5))\n",
    "\n",
    "sns.boxplot(data=p,ax=axs)\n",
    "axs.set_title('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#creating Scoring parameter: \n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score),'recall':make_scorer(recall_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# clf = MLPClassifier(random_state=40)\n",
    "\n",
    "# #creating Scoring parameter: \n",
    "# scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#            'precision': make_scorer(precision_score),'recall':make_scorer(recall_score)}\n",
    "\n",
    "# param_grid = {\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "\n",
    "# #passing the scoring function in the GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator =clf, param_grid =param_grid, scoring=scoring, refit='precision', cv=5, n_jobs=-1)\n",
    "\n",
    "# grid_search.fit(X_train_strat,y_train_strat)\n",
    "\n",
    "# df=pd.DataFrame.from_dict(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(random_state=40)\n",
    "# param_grid = {\n",
    "#  'max_depth': [10, 50, 100, None],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# #passing the scoring function in the GridSearchCV\n",
    "# grid_search2 = GridSearchCV(estimator = clf, param_grid =param_grid, scoring=scoring, refit='precision', cv=5, n_jobs=-1)\n",
    "\n",
    "# # X_train_strat_renamed = X_train_strat.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "# grid_search2.fit(X_train_strat,y_train_strat)\n",
    "\n",
    "# df2=pd.DataFrame.from_dict(grid_search2.cv_results_)\n",
    "\n",
    "\n",
    "# grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:32:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0.0: 0.9192546583850931, 1.0: 0.08074534161490683},\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 10,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(random_state = 40)\n",
    "param_grid ={\n",
    "        'class_weight':[weight],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]}\n",
    "\n",
    "#passing the scoring function in the GridSearchCV\n",
    "grid_search4 = GridSearchCV(estimator = clf, param_grid =param_grid, scoring=scoring, refit='precision', cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search4.fit(X_train_strat,y_train_strat)\n",
    "\n",
    "df4=pd.DataFrame.from_dict(grid_search4.cv_results_)\n",
    "\n",
    "grid_search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.9192546583850931, 1.0: 0.08074534161490683}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "14 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bad allocation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1654, in __init_from_np2d\n",
      "    data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n",
      "MemoryError: Unable to allocate 148. MiB for an array with shape (24601, 788) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 1474, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\", line 568, in _data_from_pandas\n",
      "    data = data.rename(columns=str)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 309, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\", line 4296, in rename\n",
      "    return super().rename(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 924, in rename\n",
      "    result = self if inplace else self.copy(deep=copy)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5663, in copy\n",
      "    data = self._mgr.copy(deep=deep)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 802, in copy\n",
      "    res = self.apply(\"copy\", deep=deep)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 406, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 679, in copy\n",
      "    values = values.copy()\n",
      "MemoryError: Unable to allocate 148. MiB for an array with shape (788, 24601) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.91925466\n",
      " 0.91925466 0.91925466 0.91925466 0.91925466 0.91925466 0.91925466\n",
      " 0.91918962 0.91925466 0.91925466 0.91922214 0.91928718 0.91925466\n",
      " 0.91925466 0.91925466 0.91925466 0.91925466 0.91925466 0.91928718\n",
      " 0.91928718 0.91925466 0.91925466 0.91925466 0.91928718 0.91922213\n",
      " 0.91915711 0.91918962 0.91922214 0.91915709 0.91928718 0.91928718\n",
      " 0.91928718 0.91925466 0.91928718 0.91928718 0.91857178 0.91853926\n",
      " 0.91824659 0.91834414 0.91844169 0.91831162 0.91824658 0.9181165\n",
      " 0.91811649 0.91834413 0.91818155 0.91857178 0.91860429 0.91883192\n",
      " 0.91909208 0.91922215 0.91928718 0.9193197  0.91928718 0.91928718\n",
      " 0.91866933 0.91814903 0.91811652 0.91844169 0.91847421 0.91850675\n",
      " 0.91808398 0.91779132 0.91821405 0.91834413 0.91850676 0.91824659\n",
      " 0.91821406 0.91889695 0.91896199 0.91925466 0.91922214 0.91928718\n",
      " 0.9193197  0.91928718]\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.2        0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.2        0.         0.2        0.2        0.2        0.2\n",
      " 0.         0.2        0.2        0.2        0.4        0.4\n",
      " 0.2        0.         0.2        0.2        0.31333333 0.1474359\n",
      " 0.14787879 0.25934066 0.16857143 0.18285714 0.1352381  0.14675325\n",
      " 0.17936508 0.16777778 0.13871795 0.08666667 0.08636364 0.17333333\n",
      " 0.2        0.3        0.4        0.4        0.2        0.2\n",
      " 0.1030303  0.0574359  0.20299145 0.18795094 0.21818182 0.09333333\n",
      " 0.08607143 0.15533911 0.16777778 0.17722944 0.13166667 0.10386555\n",
      " 0.15904762 0.22380952 0.25714286 0.5        0.1        0.3\n",
      " 0.4        0.2       ]\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00040241 0.00040241 0.\n",
      " 0.         0.         0.         0.         0.         0.00040241\n",
      " 0.00040241 0.         0.00040241 0.00040241 0.00040241 0.00040241\n",
      " 0.         0.00040241 0.00040241 0.00040241 0.00080483 0.00080483\n",
      " 0.00040241 0.         0.00040241 0.00040241 0.00241611 0.00241692\n",
      " 0.00281934 0.00281771 0.00201288 0.00322094 0.00282015 0.00281934\n",
      " 0.00281771 0.00241611 0.00241611 0.00161209 0.00120805 0.00120805\n",
      " 0.00040241 0.00080483 0.00080564 0.00080564 0.00040241 0.00040241\n",
      " 0.00201451 0.00161128 0.00362335 0.00281852 0.00281934 0.00201451\n",
      " 0.00241692 0.00362335 0.00322175 0.00281934 0.00241773 0.00241692\n",
      " 0.00281852 0.00201288 0.00161047 0.00161128 0.00040241 0.00080564\n",
      " 0.00080564 0.00040241]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0.0: 0.9192546583850931, 1.0: 0.08074534161490683},\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 10000,\n",
       " 'num_leaves': 12}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "clf = LGBMClassifier(random_state = 40)\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'class_weight':[weight],\n",
    "    'n_estimators':[10,100,1000,10000],\n",
    "    'learning_rate': [0.01,0.02,0.04,0.05],\n",
    "    'num_leaves':[12,24,34,45,56]}\n",
    "\n",
    "#passing the scoring function in the GridSearchCV\n",
    "grid_search3 = GridSearchCV(estimator = clf, param_grid =param_grid, scoring=scoring, refit='precision', cv=5, n_jobs=-1)\n",
    "\n",
    "X_train_strat_renamed = X_train_strat.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "grid_search3.fit(X_train_strat_renamed,y_train_strat)\n",
    "\n",
    "df3=pd.DataFrame.from_dict(grid_search3.cv_results_)\n",
    "grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_clf_opt={'LGBM':LGBMClassifier(random_state = 40,class_weight=weight),\n",
    "              'LGBM_opt':LGBMClassifier(random_state = 40,class_weight=weight,learning_rate=0.05,n_estimators= 10000,num_leaves= 12),\n",
    "             'XGB' :XGBClassifier(random_state = 40,class_weight=weight),\n",
    "              'XGB_opt' :XGBClassifier(random_state = 40,class_weight= weight, max_depth= 4, min_child_weight= 10,subsample= 0.8)}\n",
    "\n",
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_strat,y_train_strat, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_train = X_train_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_train_test = X_train_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "y_pred={}\n",
    "precision={}\n",
    "for i in best_clf_opt:\n",
    "    model=best_clf_opt[i]\n",
    "    model.fit(X_train_train,y_train_train)\n",
    "    y_pred[i]=model.predict(X_train_test)   \n",
    "    precision[i]=precision_score(y_train_test, y_pred[i],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBM': 0.8610682957681342,\n",
       " 'LGBM_opt': 0.8438271364431232,\n",
       " 'XGB': 0.855327438630491,\n",
       " 'XGB_opt': 0.8654425844786479}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_strat,y_train_strat, test_size=0.33, random_state=42,stratify=y_train_strat)\n",
    "\n",
    "clf_opt = XGBClassifier(random_state = 40,class_weight= weight, max_depth= 4, min_child_weight= 10,subsample= 0.8)\n",
    "clf_opt.fit(X_train_train,y_train_train)\n",
    "prb=clf_opt.predict_proba(X_train_test)\n",
    "prb=pd.DataFrame(prb)\n",
    "\n",
    "seuil_precision={}\n",
    "seuil_fbeta={}\n",
    "for i in np.arange(0,1.01,0.01):\n",
    "    prb_seuil_i=prb[1].copy()\n",
    "    prb_seuil_i[prb_seuil_i>=i] = 1\n",
    "    prb_seuil_i[prb_seuil_i<i] = 0\n",
    "    seuil_precision[i]=precision_score(y_train_test, prb_seuil_i,average='weighted')\n",
    "    seuil_fbeta[i]=fbeta_score(y_train_test,prb_seuil_i,average='weighted',beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdkElEQVR4nO3dfZRcdZ3n8fenq6sfku4kJN1JSMgDSogGFPBERMdVHNABRmHOGdeFFV0U5egsuhzZBxTHdRlm9zg+rjN4FEfHGUdAxt114hIXR0VRFCTKg5NAmJAEE5KQziNJOunuqvruH/d2p6q6Ol1Jurv6dj6vc3JOPfz63u+tW/n0r7/31i1FBGZmln1NjS7AzMzGhgPdzGyKcKCbmU0RDnQzsynCgW5mNkU40M3MpggHuh2TpC9L+tM6xq2VdPH4V3TiJC2X9LikA5I+PIHr/Zikv56A9SyVFJKax3td9Sp/X0j6pKS/b2xFU9uk2fE2OUXEB+ocd8541zIG/jPwQEScP14rSMPr7yPijMHHIuK/j9f6JruMvC+mDM/QTwGTacbWYEuAtY0uwmy8ONAzStJmSR+VtE7SXkl/I6ktfe5iSVsl/RdJO4C/kdQk6RZJz0raLeleSbPLlvd6Sb+QtE/SFknXpY9/Q9Lt6e0uSf83HbNH0s8kNZXVc2l6u1XSFyRtS/99QVJrVW03S9opabuk9xxjO2dK+lo67nlJt0vKpc9dJ+nnkj6TvgabJF0+wnJ+DLwJ+CtJByWdnS777yT1SHpO0sfLtueYy5Y0O33Nt6XPf1fSdOD7wIJ0HQclLahuNUi6Mm1F7JP0E0kvr9qv/1HSk5L2S/r24H6tsU25tL5dkjYCf1jjPXJp2f0RWx6j7NsFkv5X+jptKm9Xlb8/0vsXS9o6Ug02vhzo2fZO4A+AlwJnAx8ve24+MJtkVnoD8CHgj4A3AguAvcAdAJKWkATRXwLdwPnA4zXWdzOwNR0zD/gYUOvaEbcCF6XLOQ+4sEZtM4GFwPXAHZJOG2EbvwEUgLOAC4C3AO8re/41wHqgC/gL4GuSVL2QiPh94GfAjRHRERHPpNs7E3gJyevybqD8l8uxlv1NYBpwDjAX+HxEHAIuB7al6+iIiG3ldUg6G7gbuInkdVwNfE9SS9mwdwCXAWcCrwSuG+G1eT/w1vR1WQm8fYRx9ai5b9NQ/x7wBMn+ugS4SdIfnMS6bJw40LPtryJiS0TsAf4cuKbsuRLwXyOiLyIOAx8Abo2IrRHRB3wSeLuSdsy/BX4YEXdHxEBE7I6Ix2usbwA4HViSjvtZ1L4Y0DuB2yJiZ0T0AP8NeFfVcm5Ll7EaOAgsr16IpHnAFcBNEXEoInYCnweuLhv2XER8NSKKwN+m9c075quWLDuXLuejEXEgIjYDn62qs+ayJZ1OEtwfiIi96Xb8dLR1pv4NcF9E/FNEDACfAdqB15WN+WJEbEv36/dIfjHW8g7gC2Xvgf9RZw21jLRvXw10R8RtEdEfERuBr1K5D2yScKBn25ay28+RzLwH9UTEkbL7S4D/k/5JvQ94CiiShN8i4Nk61vdpYAPwA0kbJd0ywrgFaT0j1bY7Igpl93uBjhrLWQLkge1ldX+FZEY8aMfgjYjoTW/WWla1rnTZ1XUurGPZi4A9EbG3jvVUq3htIqJEsh9rrpeRX5vBZVW/B07USPt2CUkLaV/ZPvgYdfzStInng2XZtqjs9mKg/M/76pnzFuC9EfFQ9UIkbSFpixxTRBwg+dP8ZknnAj+W9GhE/Khq6DYqD0BW11avLUAf0FX1C2As7CKZlS4B1qWPLQaer7Ou2ZJmRcS+qudGu3zpNuAVg3fSFs6iOtdbbTvD3wPlDpG0hQbNH2lBI+1bkm3dFBHLRvjRutdh488z9Gz795LOUHJw81bg28cY+2Xgz9N+OZK6JV2VPvct4FJJ75DULGmOpPOrFyDprZLOSkNoP8kMv1RjXXcDH0/X0QV8Ajju848jYjvwA+CzkmYoObD7UklvPN5l1Vh2EbiX5DXpTF+Xj9RTZ1rX94EvSTpNUl7SG9KnXwDmSJo5wo/fC/yhpEsk5UlCtA/4xQlsxr3Ah9P3wGlA9V9MjwNXp/Uds8d+jH37K+CAkgPs7emB2HMlvbpsHVekB4nnkxwbsAZxoGfbXSSBt5GkZXL7Mcb+T2AVyZ/UB4CHSQ76ERG/I+lV3wzsIflPel6NZSwDfkjS8/4l8KWIeKDGuNuBNcCTwG+B34xS27G8G2ghmUXvBb5D0usdCx8imWFuBH5O8np+vc6ffRfJDP9pYCdpkEXE0yS/0DamLYryVhMRsR64luSA7C7gbcDbIqL/BOr/KnA/yQHL3wD/u+r5PyU5YL6X5DjGXcdYVs19m/7ieytJH39TWvNfkxxMhuTg8BPAZpL34rEmFTbO5C+4yCZJm4H3RcQPG12LmU0OnqGbmU0RDnQzsynCLRczsynCM3QzsymiYeehd3V1xdKlSxu1ejOzTPr1r3+9KyK6az3XsEBfunQpa9asadTqzcwySdKInwh2y8XMbIpwoJuZTREOdDOzKcKBbmY2RTjQzcymCAe6mdkU4UA3M5si/AUXZpPEg8/0sGbzHiTRJDH8m1En3oy2Zt712qXkmiZBMTYqB7rZJPD4ln285xuPUixNvmsrnbNwJq9eOrvRZVgdHOhmDXaor8BN9zzGvM5Wvn/TG5jR1sxkyPXt+w/z+k89wNM7DjjQM8KBbtZgt9+3juf29HLX+y5iZnsegNwk6HAsnNVOZ1sz63e82OhSrE4+KGrWQD9Yu4O7f7WFG97wEl770jmNLqeCJF42v5P1Ow40uhSrk2foZg3wLy8c4Ms/3cg/Pv48K06fwc1vXt7okmpaPr+Tf3x8GxGBJsNRWjsmB7rZcXpowy6+9vNNHOwrnNDP9xVKPLFlH+35HO967RL+5OKzaGmenH8sL5/XyYEjBbbvP8KCWe2NLsdG4UA3O4a9h/rpL5YA2L7/CJ/7p2d48Jke5s9oY2nXtBNaZnu+iQ9fsozrXreU2dNbxrLcMbd8/gwA1u844EDPAAe6WZX+Qon/t3YH33r4OR7ZtKfiuZnteW694uW867VLaMvnGlThxFk+rxOAp3cc4E0vm9vgamw0DnQ7ZfUVivxiw27uX7uDX23eM3QO+L7eAfYfHmDR7HY+8uaz6epoBSCfE29ZMZ+Z0/KNLHtCzZyW5/SZbT7TJSMc6HbK2bq3l6/9fBPfWbOVA30FOlqbueglc+hoTWbcrc05rnjl6fyrs7po8ickWT6/k6d9pksmTJlAf2jDLm6/7yna8k3Mmd7KvBmtXHjmbF5/Vhdz0hmWTX2bdh3igad3snbbixwZKNJXKFIKmNWeZ9a0FnoO9rH6t9sR8LbzFnDleQt43VlzaG2e+u2TE7V8ficPbdjFQLFEPjc5D95aYkoE+rZ9h7nxrt8wvbWZro7pPL/vMI9s2s23HvkdACtOn8H5i2fxioUzOWfBDLo7W5nZnqc9n/OpWBkSEbx4uMC+w/0MFIOBYondB/t5eseLrNv+Ir95bi+bd/cCMG9GKx2tzbQ252hqgmdeOMDeQ/1I4j2vW8p7X3+mD/LVafm8TgaKweZdh1iW9tRtcsp8oA8US3zo7sfoL5T4zgcv5KXdHQAUS8Fvn9/Pz/+lh188u5vvPbGNu9KAH9SSa6Kro4XuGW10d7QyvTVHS66JtnyO2dNbmDujlbmdbRWnlE1vyTGjPc+MtjxSsv5CMWhpbmJ6azMdrc2Zu5BRf6FEb3+BvkKJvoESvQMFtu45zHN7etmyp5edB47Qc6CP3Qf7KZR9Jr2jtZnTpuc5bVoLC2e1s3jONJbMns7ps9qY25kE6uAvzGIp2H94gN0H+9h1sJ9dB/voOdBHz8E+mgTdHa3MndFGX6HI5l29bN59iN0H+9NZdon9hwd44cUj9BVKNbdhbmcrr1g4k/e+/kwuPnsui+fUPgPF51Mfv+Xzjx4YdaBPbpkP9M/cv55fP7eXL15zwVCYA+SaxPmLZnH+olnc+PvLiAie293L0zsOsLe3n/2HB9jXO0DPgT52HjjC1r29HBko0l8ocXigyL7DA8QJXk+jo7WZWdOSoDttegtd01uY09FCe0szTYImiUKxxJFCiSMDRQaKAQyuTDQ3ieacyKe/XNryTbTnc7Tnc7TlczQ1iUN9BQ71FejtT2oeKJboL5YoloJCKYgg+ZmWJvK5pqGZ7f7eAfb29rOvd4B9hwc4eKQwdFreSNsyb0Yr3Z2tvHzBDFrSP7lLERw8UmBvbz/b9r3ID9a9QH9V2Lbnc+SaRF9hcBuHy+dEKai4KJUEC2a2M3dGK23NOTrbmlnaNZ35M1qZN6ONWdNaaGluIt8kZrbnWT6/s+62msP8+J01t4Nck1i/4wBvO6/R1dixZDrQf7VpD195cCPvfM1irjxvwTHHSmJp13SWdk2va9mDf87vPHCkLIyCQ31F9h8e4MUjSeC35Jpozon+QomDfQUO9hWGflns7e1n76F+nt15kN2H+jgyUBl4bfkksJubmpBAkIZbiUIp6C+URpyRlss1iXxONDcltTQ3JaF7ZKBIb3+BUiTBPLM9z8z2PKdNz7NgVjuzpuXpaM3T0ZqjvaWZ9nyO1uakptNntbFk9jRmT2+pKwRLpWDHi0d4bncvL7x4ZGhWXwpoaW6iJdfEzPY8XZ2tzJneQndnK90drcyalicC9vb2s/NAH/mcWDR7mnvak0hrc44zu6b7wGgGZDrQ123bD8BNl5495svO55qYP7ON+TPbxnS5EUEpoEn1zRYjgr5CicP9RY4UihzuL1KKGGrvTGs5dotncH3j3QZqahILZrWfUF9agjkdrT54PYktn9/Jk1v3NboMG0WmA32wn9uaz86Rd0nHdSU9SWnb5cRmrMe7PrNaXjavk/ue3M6GnQdpy9D/t8lq1rQWOlrHPn6nRKA3Z+wgpFnWrFiQXALg0s/9tMGVTA23/9G5XHvRkjFfbqYDvTgU6J4xmI2nN57dzV9ecwGHB4qNLmVKeNXi08ZluZkO9ELRM3SzidCca+Jto5x4YI2X6altsVRCwh/PNjMj44E+UArPzs3MUpkO9GIp3D83M0tlOg0LRc/QzcwG1RXoki6TtF7SBkm31Hh+saQHJD0m6UlJV4x9qcMVSyVyPsnazAyoI9Al5YA7gMuBFcA1klZUDfs4cG9EXABcDXxprAutxT10M7Oj6pmhXwhsiIiNEdEP3ANcVTUmgBnp7ZnAtrErcWTFonvoZmaD6knDhcCWsvtb08fKfRK4VtJWYDXwoVoLknSDpDWS1vT09JxAuZUKpcjcpWrNzMbLWE1vrwG+ERFnAFcA35Q0bNkRcWdErIyIld3d3Se90mKpRLN76GZmQH2B/jywqOz+Gelj5a4H7gWIiF8CbUDXWBR4LAOeoZuZDakn0B8Flkk6U1ILyUHPVVVjfgdcAiDp5SSBfvI9lVEUi0HePXQzM6COQI+IAnAjcD/wFMnZLGsl3SbpynTYzcD7JT0B3A1cF3Gi3/dTP/fQzcyOquviXBGxmuRgZ/ljnyi7vQ74vbEtbXQF99DNzIZkul9R9AzdzGxIpgO94B66mdmQTKehZ+hmZkdlOtAH3EM3MxuS6UD3DN3M7KhMB3rB13IxMxuS6TQs+mqLZmZDMh3oA74eupnZkEwHumfoZmZHZTrQ3UM3Mzsq02noGbqZ2VGZDvSCe+hmZkMyHuieoZuZDcp0oPs7Rc3Mjsp0GhZK4Y/+m5mlMh7oJX/038wslfFAdw/dzGxQZgO9VAoicA/dzCyV2TQslJKvLHUP3cwskeFALwG4h25mlspwoKczdAe6mRmQ4UAvFh3oZmblMhvogzP0XC6zm2BmNqYym4aDPXTP0M3MEtkNdLdczMwqZDbQiz5t0cysQmYDfaiH7g8WmZkBmQ5099DNzMplN9DdQzczq5DZQHcP3cysUmYD3T10M7NKmU3DQtE9dDOzcpkN9KKv5WJmViGzge7L55qZVaor0CVdJmm9pA2SbhlhzDskrZO0VtJdY1vmcEX30M3MKjSPNkBSDrgDeDOwFXhU0qqIWFc2ZhnwUeD3ImKvpLnjVfCgAffQzcwq1DO9vRDYEBEbI6IfuAe4qmrM+4E7ImIvQETsHNsyh/Npi2ZmleoJ9IXAlrL7W9PHyp0NnC3pIUkPS7qs1oIk3SBpjaQ1PT09J1Zxyl9wYWZWaawa0M3AMuBi4Brgq5JmVQ+KiDsjYmVErOzu7j6pFbqHbmZWqZ40fB5YVHb/jPSxcluBVRExEBGbgGdIAn7cuIduZlapnkB/FFgm6UxJLcDVwKqqMd8lmZ0jqYukBbNx7Moczj10M7NKowZ6RBSAG4H7gaeAeyNiraTbJF2ZDrsf2C1pHfAA8J8iYvd4FQ3lH/13oJuZQR2nLQJExGpgddVjnyi7HcBH0n8T4uhH/91DNzODKfBJUc/QzcwSmQ30wR563j10MzMgw4HuGbqZWaXsBvrQNxZldhPMzMZUZtOwmH6nqCfoZmaJzAZ6oRTkc0JyopuZQYYDvVgK98/NzMpkNtAHiuH+uZlZmcwmYrFU8gzdzKxMZgN9sIduZmaJzAa6e+hmZpUyG+juoZuZVcpsIrqHbmZWKbOBXiiFr4VuZlYms4FeLIW/rcjMrExmA32gGP4+UTOzMplNxGKp5Bm6mVmZzAa6e+hmZpUyG+juoZuZVcpsoBeK/mCRmVm57AZ6qUQ+l9nyzczGXGYT0R/9NzOrlNlAL7iHbmZWIbuB7h66mVmF7AZ6qUSze+hmZkMym4g+bdHMrFJmA73gg6JmZhWyG+hFz9DNzMplN9BL4R66mVmZzCaiL85lZlYps4HuHrqZWaXsBrp76GZmFTIb6EX30M3MKmQ2EQvuoZuZVagr0CVdJmm9pA2SbjnGuD+WFJJWjl2Jw5VKQSlwD93MrMyogS4pB9wBXA6sAK6RtKLGuE7gPwCPjHWR1QqlAPAM3cysTD0z9AuBDRGxMSL6gXuAq2qM+zPgU8CRMayvpuJgoLuHbmY2pJ5EXAhsKbu/NX1siKRXAYsi4r5jLUjSDZLWSFrT09Nz3MUOKpRKgGfoZmblTnqKK6kJ+Bxw82hjI+LOiFgZESu7u7tPeJ2DM3T30M3Mjqon0J8HFpXdPyN9bFAncC7wE0mbgYuAVeN5YHSg6B66mVm1egL9UWCZpDMltQBXA6sGn4yI/RHRFRFLI2Ip8DBwZUSsGZeKcQ/dzKyWURMxIgrAjcD9wFPAvRGxVtJtkq4c7wJrGeyhu+ViZnZUcz2DImI1sLrqsU+MMPbiky/r2ApuuZiZDZPJnkXBB0XNzIbJZKAP9tDz7qGbmQ3JZCK6h25mNlw2A909dDOzYbIZ6O6hm5kNk8lAdw/dzGy4TCaie+hmZsNlM9DdQzczGyaTge6Lc5mZDZfJQC+4h25mNkwmE7HoHrqZ2TCZDHRfPtfMbLhMBrp76GZmw2Uy0N1DNzMbLpOJ6B66mdlwmQx099DNzIbLZKC7h25mNlwmA73g7xQ1Mxsmk4k42EN3y8XM7KhMBvpgD90tFzOzozIZ6L58rpnZcJlMxMEeuifoZmZHZTLQi6USzU1CcqKbmQ3KZKAXiuH+uZlZlWwGeincPzczq5LJVCyWPEM3M6uWyUAvpD10MzM7KpuB7h66mdkw2Qx099DNzIbJZCq6h25mNlwmA71QCvfQzcyqZDPQiyXP0M3MqmQz0EvhS+eamVXJZCoW3XIxMxumrkCXdJmk9ZI2SLqlxvMfkbRO0pOSfiRpydiXelTBB0XNzIYZNdAl5YA7gMuBFcA1klZUDXsMWBkRrwS+A/zFWBdarlD0B4vMzKrVM0O/ENgQERsjoh+4B7iqfEBEPBARvendh4EzxrbMSkkP3YFuZlaunkBfCGwpu781fWwk1wPfr/WEpBskrZG0pqenp/4qqyQ99Ey2/83Mxs2YpqKka4GVwKdrPR8Rd0bEyohY2d3dfcLrcQ/dzGy45jrGPA8sKrt/RvpYBUmXArcCb4yIvrEprzb30M3Mhqtnhv4osEzSmZJagKuBVeUDJF0AfAW4MiJ2jn2ZlYruoZuZDTNqoEdEAbgRuB94Crg3ItZKuk3SlemwTwMdwD9IelzSqhEWNyYK7qGbmQ1TT8uFiFgNrK567BNlty8d47qOyR/9NzMbLpPTXF+cy8xsuEwGunvoZmbDZTLQk9MWM1m6mdm4yWQq+rRFM7Phshno/mCRmdkwmQz0YinIu4duZlYhk4HuHrqZ2XCZTEX30M3MhstcoJdKQSlwD93MrErmAr0YAeAeuplZlewFeikJdPfQzcwqZS4VB4olAPfQzcyqZC7Qj87QHehmZuUyF+iFknvoZma1ZC7Q3UM3M6stc6noHrqZWW2ZC3T30M3MastcoA/20H09dDOzSpkL9MEZur9T1MysUuZScbCH7paLmVmlzAV60actmpnVlLlAL/igqJlZTZkLdPfQzcxqy1wquoduZlZb5gLdPXQzs9oyF+juoZuZ1Za5QC8W3UM3M6slc6lYKLmHbmZWSwYD3T10M7NaMhfovjiXmVltmQv0gnvoZmY1ZS4Vh3robrmYmVXIYKCnPXS3XMzMKmQu0N1DNzOrra5Al3SZpPWSNki6pcbzrZK+nT7/iKSlY15pyj10M7PaRk1FSTngDuByYAVwjaQVVcOuB/ZGxFnA54FPjXWhg9xDNzOrrZ5p7oXAhojYGBH9wD3AVVVjrgL+Nr39HeASSeOSuEvnTOeKV8z3eehmZlWa6xizENhSdn8r8JqRxkREQdJ+YA6wq3yQpBuAGwAWL158QgW/5Zz5vOWc+Sf0s2ZmU9mENqIj4s6IWBkRK7u7uydy1WZmU149gf48sKjs/hnpYzXHSGoGZgK7x6JAMzOrTz2B/iiwTNKZklqAq4FVVWNWAf8uvf124McREWNXppmZjWbUHnraE78RuB/IAV+PiLWSbgPWRMQq4GvANyVtAPaQhL6ZmU2geg6KEhGrgdVVj32i7PYR4F+PbWlmZnY8/OkcM7MpwoFuZjZFONDNzKYINepkFEk9wHMn+ONdVH1o6RTgbT41eJtPDSezzUsiouYHeRoW6CdD0pqIWNnoOiaSt/nU4G0+NYzXNrvlYmY2RTjQzcymiKwG+p2NLqABvM2nBm/zqWFctjmTPXQzMxsuqzN0MzOr4kA3M5siJnWgT6bvMp0odWzzRyStk/SkpB9JWtKIOsfSaNtcNu6PJYWkzJ/iVs82S3pHuq/XSrpromsca3W8txdLekDSY+n7+4pG1DlWJH1d0k5J/zzC85L0xfT1eFLSq056pRExKf+RXNnxWeAlQAvwBLCiasyfAF9Ob18NfLvRdU/ANr8JmJbe/uCpsM3puE7gQeBhYGWj656A/bwMeAw4Lb0/t9F1T8A23wl8ML29Atjc6LpPcpvfALwK+OcRnr8C+D4g4CLgkZNd52SeoU+q7zKdIKNuc0Q8EBG96d2HSb5wJMvq2c8Af0by5eNHJrK4cVLPNr8fuCMi9gJExM4JrnGs1bPNAcxIb88Etk1gfWMuIh4kuZz4SK4C/i4SDwOzJJ1+MuuczIFe67tMF440JiIKwOB3mWZVPdtc7nqS3/BZNuo2p3+KLoqI+yaysHFUz34+Gzhb0kOSHpZ02YRVNz7q2eZPAtdK2kpyue4PTUxpDXO8/99HVdf10G3ykXQtsBJ4Y6NrGU+SmoDPAdc1uJSJ1kzSdrmY5K+wByW9IiL2NbKocXYN8I2I+Kyk15J8ac65EVFqdGFZMZln6Kfid5nWs81IuhS4FbgyIvomqLbxMto2dwLnAj+RtJmk17gq4wdG69nPW4FVETEQEZuAZ0gCPqvq2ebrgXsBIuKXQBvJRaymqrr+vx+PyRzop+J3mY66zZIuAL5CEuZZ76vCKNscEfsjoisilkbEUpLjBldGxJrGlDsm6nlvf5dkdo6kLpIWzMYJrHGs1bPNvwMuAZD0cpJA75nQKifWKuDd6dkuFwH7I2L7SS2x0UeCRzlKfAXJzORZ4Nb0sdtI/kNDssP/AdgA/Ap4SaNrnoBt/iHwAvB4+m9Vo2se722uGvsTMn6WS537WSStpnXAb4GrG13zBGzzCuAhkjNgHgfe0uiaT3J77wa2AwMkf3FdD3wA+EDZPr4jfT1+Oxbva3/038xsipjMLRczMzsODnQzsynCgW5mNkU40M3MpggHupnZFOFANzObIhzoZmZTxP8H05+oAcAuhJ4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(seuil_precision.items()) \n",
    "x, y = zip(*lists) \n",
    "plt.plot(x, y)\n",
    "plt.title('precision en fonction du seuil')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdnklEQVR4nO3de5hcdZ3n8fenq2+5dG6kMZCEhDtExgtm8TajsDoIPCPMPN5gxcvKyuou7q6OOs7iMIrj7Diu+owrjuLoMOIFUVc3jvgw44CiCEp4BJQAEpMguUC6c+n0tbqq67t/nNOhaLrTlaS6q+ucz+t5+knVOafP+f6q0p/zq985dY4iAjMza34tjS7AzMzqw4FuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4UDPAUmnS7pPUr+k/ybpBkl/1ei6jpakeZK+J6lP0jdncbt/IOmRWdrWNkmvnI1t1ULS5yT9Rfr4XEnbG12TPaW10QXYrHg/cHtEPA9A0g1HuqL0d7dHxAfrUtnReS3wLOCYiCjP1EYkBXBqRGwGiIifAKfP1Pbmsoh4R6NrsKm5h54Pa4AHG13EDFgD/GYmw9ysmTjQM07SbcB5wGckDUg6LZ21XNK/psMwP5a0pup3zkjn7ZX0iKTXp9OvBN4IvD9d1/fS6R+Q9Nt0XZsk/ckh6mmpWn6PpJslLUvnrZUUkt4i6XeSeiVdPcV6PgxcA7whreWKdN0flPSYpN2SvixpcS3rllSQ9D+r2nGvpNWS7kgXuT/dzhsmDjVIOlPSjyTtl/SgpIur5t0g6TpJ30/X+3NJJx/i9XlTWv+eiW2fOFR2qCEPJT6Vvg4HJP1K0lnpvA5J/zt9HZ5Mh1HmpfPeKumnE9YVkk6ZrAabWxzoGRcR/x74CXBVRCyMiN+ks94IfARYDtwHfBVA0gLgX4GvAccClwKflbQuIq5Pl/vbdF2vTtf1W+APgMXAh4GvSDpuipLeBfwx8HLgeGAfcN2EZX6fZEjjFcA1ks6cpF1/Cfw18I20li8Cb01/zgNOAhYCn6lx3e8BLgMuAhYBbwOGIuJl6fznptv5RvXKJLUB3wP+JX293gV8VVL1kMyl6euyFNgMfHSyF0bSOuDvgTelr80xwKrJlq3B+cDLgNNI3pfXA3vSeX+TTn8ecAqwkmTnaE3OgZ5f34+IOyKiCFwNvFjSauCPgG0R8Y8RUY6IXwLfBl431Yoi4psRsTMiKmngPQqcM8Xi7wCujojt6bY/BLxWUvXxnA9HxHBE3A/cDzy3xja9EfhkRGyJiAHgz4FLa1z3fwI+GBGPROL+iNjD9F5EsuP4m4gYjYjbgH8m2TmM+05E/CIdGvoqSZBO5rXAP1e9L38BVGpq+TOVgC7gDEAR8VBE7JIk4Erg3RGxNyL6SXaMlx7hdmwO8UHR/Hp8/EFEDEjaS9IrXAO8UNL+qmVbgRunWpGkN5P0cNemkxaS9Pwnswb4jqTqoBojObg57omqx0Pp+mpxPPBY1fPHSGqvZd2rST5pHK7jgccjoro9j5H0eqfb5qTrGn8SEYOSatmpPENE3CbpMySfftZI+r/Ae4FOYD5wb5LtAAgoHMl2bG5xDz2/Vo8/kLQQWAbsJAmUH0fEkqqfhRHxznTxp12eMx17/wJwFcnZJkuAX5OExGQeBy6csP7OiNhRhzbtJNlhjDsBKANP1vC7jwNTjm1Ps83Vkqr/lk4AjqQ9u3j6+zKfZNhl3CBJGI9bcaiVRcSnI+IFwDqSIZb3Ab3AMPDsqtd/cUSM72Setg1Jh9yGzS0O9Py6SNLvS2onGUu/OyIeJxkuOC09ONeW/vy7qrHmJ0nGp8ctIAn5HgBJ/xE46xDb/Rzw0XRHgKRuSZfUqU1fB94t6cR0JzU+xl7LWTD/AHxE0qnpAcXnSBoP04ltrvZzkl73+9PX6lzg1cBNR1D/t4A/qnpfruXpf6P3kbxvy9Kg/R9TrSh9z16YjvEPAiNAJf0k8QXgU5KOTZddKelV6a/eDzxb0vMkdZIMiVmTcKDn19eAvwT2Ai8ALgdIx1TPJxlT3UkyXPAxoCP9vS8C69IzOr4bEZuATwB3kQTf7wF3HmK7fwdsAP5FUj9wN/DCOrXpSyRDQ3cAW0lC7F01/u4ngZtJDm4eIGnnvHTeh4B/Stv8+upfiohRkgC/kKT3+1ngzRHx8OEWHxEPAv+V5L3ZRXLAuPoslhtJAndbWuc3mNoikuDeRzIEtAf4eDrvz0gOzt4t6QDwQ9Lz6tOD5tem0x4Ffoo1DfkGF2Zm2eAeuplZRjjQzcwywoFuZpYRDnQzs4xo2BeLli9fHmvXrm3U5s3MmtK9997bGxHdk81rWKCvXbuWjRs3NmrzZmZNSdJjU83zkIuZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeE7FuVMpRIMjpYZLI4xNFpmdKxCqRyUKskNd1okIoL+kTJ9wyX6hkuMlMYoliuMliu0t7Ywv73AgvZWlsxvY3lXB8sXdLBicSftre4fmDWSA30OigiGRsc4MFJipFRheHSMYnmM0XKF0bEKAyNlnjgwwhN9I/QMFOkfKdM/UmKwOMZIaYyR8hjlsaCt0EJHawstEgPFMgeGS/QXa7nXw+FrEaxcOo81yxawYnEnxyxsZ/mCDjrbCxQkWgSthRbaCqK9kAT/WARjlaC90MLCzla6OttobRFjlaBcSS7r3FbQwXYs6GhlfnuBeW0FWgveeZhN5EBvkL2Dozy86wAPP9HPY3sG2dmXBnR/kb1Do4yWp783cHtrC90LO+jqbGVRZxvHLGyns7VAZ1sLbYUWSmMViuUKlQgWdrSxaF4Sml0drSzoaGVBR4H2QrJsoZDeMS4gCBZ1trF4XvLT2V6go7WFtpYWRseSHczgaJl9gyV6B4r09BfZvm+IbXuGeGzPIFt6BugdGGV07Ejvbzy9FiXtby+00N6atqFFVCpBJUCCjtYWOloLzGsvsHheG0vnt7GwM/kvXwlIbgXwzPsBTHWLgPHpMcnvHK62Qgvz2pLaOtuSn+R5C/Pakh1X2xzYaUnQ2VY4uCPVVDcWtMOyZH47CzvqH78O9BkUEewdHGXH/mF27BvmkSf7+fWOPn61o48nDxQPLtfV2crxi+dx3JJOzljRxbKF7Syb386ieW10tiV/+B2tBdpbk57q/PZWVizuZOn8NjTLf2GdLUn4LF3QzqqlUy8XEQwUy4yUkh3KWCX5GR2rHNxZFVpEi0RprMJAMfmUUR4LWgui0NJCRFAeC0pjFUbKYwyNjjE8mvw7/mlltFyhNJb8lCtBi0RBohJBsVyhmP7evqFRtvYOMlAsI0iDSUiT3/x0qpdV6dJH87JHQLmS7BiHSmNT7kAsu/7qj8/i8hetmX7Bw+RAr7PH9w5xx6M9/GzzHu7asoe9g6MH50lwcvdCXnLycp59/CLOWLGI01d00d3VcYg1NidJyaeBzkZXMrdFJDu5kdEKQ6Uyw6NjDJeSHVdprPFJHxEMl5Kd4khprA6fTQzg7BMO0Rs6Cg70OugfKXHLr3bx7Xt38IttewFYsaiTc0/v5qzjF7Ny6TxWLpnHicsXsGAGPmZZ85JER2vyCWwxbY0ux5qc0+UoDBbL/OOdW/n8j7fQXyxzUvcC3veq07ngrBWctHzBrA+HmFm+OdCPwFgl+Novfsff/fBRegeK/OG6Z/HOc0/m+auXOMTNrGEc6Ifpge37ufo7v+ZXO/o4Z+0yPv+ms3nBmmWNLsvMzIFeq9Fyhf/1g4e44WfbWL6wg09f9nxe/Zzj3CM3sznDgV6DvqES//krG7l7y17e/OI1vPdVp7Oo0wewzGxucaBP43d7hnjrDb9g+95hPvWG5/Inz1/V6JLMzCblQD+Erb2DvPbvf8ZYBDdecQ4vPOmYRpdkZjYlB/oU9g2O8rYb7qESwbfe8RJOOXZho0syMzukmi4WIekCSY9I2izpA5PMP0HS7ZJ+KekBSRfVv9TZM1Ia48obN7Jj/zBfePN6h7mZNYVpA11SAbgOuBBYB1wmad2ExT4I3BwRzwcuBT5b70JnS0TwZ99+gHu27eMTr3su69f6lEQzaw619NDPATZHxJaIGAVuAi6ZsEwAi9LHi4Gd9Stxdn3vgV38v/t28t7zT+PVzz2+0eWYmdWslkBfCTxe9Xx7Oq3ah4DLJW0HbgHeNdmKJF0paaOkjT09PUdQ7swaKJb56Pc3cdbKRbzz3FMaXY6Z2WGp1wWXLwNuiIhVwEXAjZKese6IuD4i1kfE+u7u7jptun7+z22P8uSBIh+++CwKLf7CkJk1l1oCfQewuur5qnRatSuAmwEi4i6gE1hejwJny+bdA3zpp1t53QtW8YI1M3NpSzOzmVRLoN8DnCrpREntJAc9N0xY5nfAKwAknUkS6HNvTGUKEcGHv/cgnW0F3n/BGY0ux8zsiEwb6BFRBq4CbgUeIjmb5UFJ10q6OF3sT4G3S7of+Drw1ojmuQ/LXVv28JNHe3n3K0/L5M0mzCwfavpiUUTcQnKws3raNVWPNwEvrW9ps+cffrKVYxa08x9eeEKjSzEzO2KNvwttg23ePcBtD+/mTS9eQ2dbodHlmJkdsdwH+pfu3Ep7a8uM3LDVzGw25TrQ9w6O8u17t/Oas1eyfKHHzs2sueU60L9y92MUyxXe9tITG12KmdlRy22gF8tjfPmuxzj39G5OfVZXo8sxMztquQ30nz7aS+9Akbe8ZG2jSzEzq4vcBvrtj+xmQXuBl5zsm1aYWTbkMtAjgtsf7uGlpyyno9WnKppZNuQy0DfvHmDH/mHOO+PYRpdiZlY3uQz02x/ZDcC5p8+9Kz6amR2pfAb6wz2csaKL4xbPa3QpZmZ1k7tA7x8pcc+2vZx7uodbzCxbchfod27upVwJzvNwi5llTO4C/faHe+jqbOVs38TCzDImV4EeEdz+yG5edmo3bYVcNd3MciBXqfbwE/3s7i/ycg+3mFkG5SrQH9i+H4Bz1i5rbCFmZjMgV4G+aecBFrQXOGHZ/EaXYmZWd/kK9F0HOPO4RbS0qNGlmJnVXW4CvVIJHtrVz7rjFzW6FDOzGZGbQH983xADxTLrjnOgm1k25SbQN+08AOAeupllVn4CfdcBCi3iNN+dyMwyKj+BvvMAJ3cvoLPN1z83s2zKT6DvOuDxczPLtFwE+t7BUXb1jXj83MwyLReB/tCu9IDocYsbXImZ2czJRaCPn+Fy5nE+IGpm2ZWPQN91gBWLOjlmYUejSzEzmzH5CPSdBzx+bmaZl/lAHymNsblnwGe4mFnmZT7QH31ygLFKuIduZpmX+UDf0jsAwCnHLmxwJWZmMyvzgb593zAAq5bOa3AlZmYzKxeBfsyCdua3tza6FDOzGZWDQB9y79zMciHzgb5j3zArHehmlgM1BbqkCyQ9ImmzpA9MsczrJW2S9KCkr9W3zCNTqQTb9w+zaqnvIWpm2TftwLKkAnAd8IfAduAeSRsiYlPVMqcCfw68NCL2STp2pgo+HL2DRUbLFQ+5mFku1NJDPwfYHBFbImIUuAm4ZMIybweui4h9ABGxu75lHhmf4WJmeVJLoK8EHq96vj2dVu004DRJd0q6W9IFk61I0pWSNkra2NPTc2QVH4bxQF+5xEMuZpZ99Too2gqcCpwLXAZ8QdKSiQtFxPURsT4i1nd3d9dp01Pbvm8IwAdFzSwXagn0HcDqquer0mnVtgMbIqIUEVuB35AEfENt3zfM0vltLOzwOehmln21BPo9wKmSTpTUDlwKbJiwzHdJeudIWk4yBLOlfmUemR37fIaLmeXHtIEeEWXgKuBW4CHg5oh4UNK1ki5OF7sV2CNpE3A78L6I2DNTRddq+74hVi7xcIuZ5UNNYxERcQtwy4Rp11Q9DuA96c+cEBFs3zfMeafPiTMozcxmXGa/Kdo7MErR56CbWY5kNtDHz3DxGLqZ5UVmA33H/vRLRcvcQzezfMhsoD/1pSIHupnlQ4YDfYjF89ro6mxrdClmZrMiw4E+7AOiZpYrmQ30HQ50M8uZTAb6+DnoviiXmeVJJgN97+Aow6Ux99DNLFcyGei+DrqZ5VEmA31neg768T5l0cxyJJOBvm+oBMAxC9sbXImZ2ezJZKD3DSeBvniez0E3s/zIZKDvHx6lvdDCvLZCo0sxM5s1mQz0vqESi+e3IanRpZiZzZpsBvpwycMtZpY7mQz0/UMlljjQzSxnMhno7qGbWR5lN9DnO9DNLF8yG+hL5vkcdDPLl8wFemmswkCx7CEXM8udzAX6gfRLRUs85GJmOZO5QN/vb4maWU5lL9DT67j4oKiZ5U3mAv2Ae+hmllOZC/T9w6MA/mKRmeVO5gK9b2j8oKhPWzSzfMlcoI8fFF3U2drgSszMZlfmAr1vuERXRyuthcw1zczskDKXen1DJRZ5/NzMcih7gT5c8peKzCyXMhfo+x3oZpZT2Qv0oVGfg25muZS5QO8bLrPYV1o0sxzKVKBHBH3D7qGbWT5lKtCHS2OUxsJj6GaWS5kK9IMX5nIP3cxyqKZAl3SBpEckbZb0gUMs9xpJIWl9/UqsXd/4tdAd6GaWQ9MGuqQCcB1wIbAOuEzSukmW6wL+O/DzehdZK18618zyrJYe+jnA5ojYEhGjwE3AJZMs9xHgY8BIHes7LH3plRY95GJmeVRLoK8EHq96vj2ddpCks4HVEfH9Q61I0pWSNkra2NPTc9jFTufgkIuvtGhmOXTUB0UltQCfBP50umUj4vqIWB8R67u7u49208/gg6Jmlme1BPoOYHXV81XptHFdwFnAjyRtA14EbGjEgdG+4RKtLWJBe2G2N21m1nC1BPo9wKmSTpTUDlwKbBifGRF9EbE8ItZGxFrgbuDiiNg4IxUfwv7hEovntSFptjdtZtZw0wZ6RJSBq4BbgYeAmyPiQUnXSrp4pgs8HH3DJZ/hYma5VdNtfSLiFuCWCdOumWLZc4++rCPTN1TyOehmlluZ+qZoXzrkYmaWR5kK9P3Doz5l0cxyK1uBPuQeupnlV2YCfawS9I+UHehmlluZCfQDB78l6kA3s3zKTKCPf+3fPXQzy6vMBPp+99DNLOcyE+juoZtZ3mUm0PcP+dK5ZpZvmQn0/pEyAIsc6GaWU5kL9K4OB7qZ5VNmAn2gWKLQIjrbMtMkM7PDkpn0Gxgp09XZ6kvnmlluZSbQ+0fKLOyo6eKRZmaZlJ1ALzrQzSzfMhPoAyNlFnX6gKiZ5VdmAr2/WGJhp3voZpZfmQn0AY+hm1nOZSfQi8lZLmZmeZWZQD8wUvaQi5nlWiYCvVgeY7RcoctDLmaWY5kI9MHiGABdPsvFzHIsE4HeP5JcOtcHRc0szzIS6MmFuTyGbmZ5lolAHyimV1p0oJtZjmUi0H3pXDOzjAT6QDEdQ3cP3cxyLBuBPuIhFzOzTAT6gfGDoj7LxcxyLBOBPlAs01YQHa2ZaI6Z2RHJRAL2j5To6mzz3YrMLNcyEei+0qKZWVYC3XcrMjPLRqAfGPGlc83MMhHoAw50M7OMBLqHXMzMshHo42e5mJnlWU2BLukCSY9I2izpA5PMf4+kTZIekPRvktbUv9TJRUTSQ/eQi5nl3LSBLqkAXAdcCKwDLpO0bsJivwTWR8RzgG8Bf1vvQqdSLFcojYWHXMws92rpoZ8DbI6ILRExCtwEXFK9QETcHhFD6dO7gVX1LXNq41daXOQeupnlXC2BvhJ4vOr59nTaVK4AfjDZDElXStooaWNPT0/tVR7C+LXQPeRiZnlX14Oiki4H1gMfn2x+RFwfEesjYn13d3ddtjlw8MJcPihqZvlWS7d2B7C66vmqdNrTSHolcDXw8ogo1qe86Y3fT9TnoZtZ3tXSQ78HOFXSiZLagUuBDdULSHo+8Hng4ojYXf8yp9Zf9KVzzcyghkCPiDJwFXAr8BBwc0Q8KOlaSReni30cWAh8U9J9kjZMsbq6880tzMwSNaVgRNwC3DJh2jVVj19Z57pq9tSQi8fQzSzfmv6bouNnuSzoKDS4EjOzxmr6QO8vlmlvbaGj1YFuZvnW/IE+UvaXiszMyECg+25FZmaJ5g90X5jLzAzIQKD3j5To8rdEzcyyEOjuoZuZQQYCfaBYpstj6GZmzR/o/b6fqJkZ0OSB7rsVmZk9pakDfaRUYawSvnSumRlNHui+dK6Z2VOaO9CLvtKimdm4pg70p+5W5EA3M2vqQO8/eC10j6GbmTV1oA8UkzF099DNzJo80Pt9tyIzs4OaOtB7BpJ7US9d0N7gSszMGq+pA31b7yDdXR0ecjEzo+kDfYgTj1nQ6DLMzOaEpg70Lb2DnLjcgW5mBk0c6P0jJXoHiqx1oJuZAU0c6Nt6hwDcQzczSzVtoG/pHQDgpG4HupkZNHGgb+0dRIITls1vdClmZnNC0wb6tt5Bjl88j862QqNLMTObE5o20Lf2Dnq4xcysSlMGekSwpXeQtT4H3czsoKYM9L2Do/SPlH2Gi5lZlaYM9K29gwCc6CEXM7ODmjLQt4wHuodczMwOaspA39Y7SGuLWLV0XqNLMTObM5oy0Lf2DnLCsvm0FpqyfDOzGdGUibjVF+UyM3uGpgv0SiXYtseBbmY2UdMF+hMHRhgpVXyVRTOzCZou0LelZ7ic5EA3M3uamgJd0gWSHpG0WdIHJpnfIekb6fyfS1pb90pTW3wOupnZpKYNdEkF4DrgQmAdcJmkdRMWuwLYFxGnAJ8CPlbvQscd29XB+euexbO6OmdqE2ZmTamWuyufA2yOiC0Akm4CLgE2VS1zCfCh9PG3gM9IUkREHWsF4Pxnr+D8Z6+o92rNzJpeLUMuK4HHq55vT6dNukxElIE+4JiJK5J0paSNkjb29PQcWcVmZjapWT0oGhHXR8T6iFjf3d09m5s2M8u8WgJ9B7C66vmqdNqky0hqBRYDe+pRoJmZ1aaWQL8HOFXSiZLagUuBDROW2QC8JX38WuC2mRg/NzOzqU17UDQiypKuAm4FCsCXIuJBSdcCGyNiA/BF4EZJm4G9JKFvZmazqJazXIiIW4BbJky7purxCPC6+pZmZmaHo+m+KWpmZpNzoJuZZYQadexSUg/w2BH++nKgt47lNAO3OR/c5nw4mjaviYhJz/tuWKAfDUkbI2J9o+uYTW5zPrjN+TBTbfaQi5lZRjjQzcwyolkD/fpGF9AAbnM+uM35MCNtbsoxdDMze6Zm7aGbmdkEDnQzs4yY04E+l259N1tqaPN7JG2S9ICkf5O0phF11tN0ba5a7jWSQlLTn+JWS5slvT59rx+U9LXZrrHeavi/fYKk2yX9Mv3/fVEj6qwXSV+StFvSr6eYL0mfTl+PBySdfdQbjYg5+UNyIbDfAicB7cD9wLoJy/wX4HPp40uBbzS67llo83nA/PTxO/PQ5nS5LuAO4G5gfaPrnoX3+VTgl8DS9Pmxja57Ftp8PfDO9PE6YFuj6z7KNr8MOBv49RTzLwJ+AAh4EfDzo93mXO6hH7z1XUSMAuO3vqt2CfBP6eNvAa+QpFmssd6mbXNE3B4RQ+nTu0muT9/ManmfAT5Ccq/akdksbobU0ua3A9dFxD6AiNg9yzXWWy1tDmBR+ngxsHMW66u7iLiD5OqzU7kE+HIk7gaWSDruaLY5lwO9bre+ayK1tLnaFSR7+GY2bZvTj6KrI+L7s1nYDKrlfT4NOE3SnZLulnTBrFU3M2pp84eAyyVtJ7m667tmp7SGOdy/92nVdPlcm3skXQ6sB17e6FpmkqQW4JPAWxtcymxrJRl2OZfkU9gdkn4vIvY3sqgZdhlwQ0R8QtKLSe6xcFZEVBpdWLOYyz30PN76rpY2I+mVwNXAxRFRnKXaZsp0be4CzgJ+JGkbyVjjhiY/MFrL+7wd2BARpYjYCvyGJOCbVS1tvgK4GSAi7gI6SS5ilVU1/b0fjrkc6Hm89d20bZb0fODzJGHe7OOqME2bI6IvIpZHxNqIWEty3ODiiNjYmHLropb/298l6Z0jaTnJEMyWWayx3mpp8++AVwBIOpMk0HtmtcrZtQF4c3q2y4uAvojYdVRrbPSR4GmOEl9E0jP5LXB1Ou1akj9oSN7wbwKbgV8AJzW65llo8w+BJ4H70p8Nja55pts8Ydkf0eRnudT4PotkqGkT8Cvg0kbXPAttXgfcSXIGzH3A+Y2u+Sjb+3VgF1Ai+cR1BfAO4B1V7/F16evxq3r8v/ZX/83MMmIuD7mYmdlhcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLi/wP3MkE9FmSe6gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(seuil_fbeta.items()) \n",
    "x, y = zip(*lists) \n",
    "plt.plot(x, y)\n",
    "plt.title('fbeta en fonction du seuil')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.007980711863207462,\n",
       " 0.01: 0.09818033648065438,\n",
       " 0.02: 0.33497264187279274,\n",
       " 0.03: 0.5281660720985567,\n",
       " 0.04: 0.6350487737052538,\n",
       " 0.05: 0.7057426040172882,\n",
       " 0.06: 0.7516698360093003,\n",
       " 0.07: 0.7813903015529436,\n",
       " 0.08: 0.803683784699034,\n",
       " 0.09: 0.8190684285221077,\n",
       " 0.1: 0.8304646331075367,\n",
       " 0.11: 0.838636222831558,\n",
       " 0.12: 0.8457022759096277,\n",
       " 0.13: 0.8506241609894215,\n",
       " 0.14: 0.8540827568291968,\n",
       " 0.15: 0.8556827558764276,\n",
       " 0.16: 0.8583215427288375,\n",
       " 0.17: 0.8606816622371256,\n",
       " 0.18: 0.862162477605602,\n",
       " 0.19: 0.8631917210596659,\n",
       " 0.2: 0.8636729183209719,\n",
       " 0.21: 0.864036692025308,\n",
       " 0.22: 0.8654627679416516,\n",
       " 0.23: 0.8662076740546084,\n",
       " 0.24: 0.866680086318267,\n",
       " 0.25: 0.866299976862844,\n",
       " 0.26: 0.867132224535781,\n",
       " 0.27: 0.8678034733953094,\n",
       " 0.28: 0.8681020625738445,\n",
       " 0.29: 0.8680374902490388,\n",
       " 0.3: 0.8689415260331557,\n",
       " 0.31: 0.8693541715013169,\n",
       " 0.32: 0.8687694659638935,\n",
       " 0.33: 0.8676027541207647,\n",
       " 0.34: 0.8657574044640896,\n",
       " 0.35000000000000003: 0.8646043626149398,\n",
       " 0.36: 0.8644646893046174,\n",
       " 0.37: 0.864151760610287,\n",
       " 0.38: 0.8643264403396329,\n",
       " 0.39: 0.8635775057506236,\n",
       " 0.4: 0.863787876333998,\n",
       " 0.41000000000000003: 0.8635007196370778,\n",
       " 0.42: 0.8628868881406607,\n",
       " 0.43: 0.8625202562198814,\n",
       " 0.44: 0.8622145652370501,\n",
       " 0.45: 0.8623261422954236,\n",
       " 0.46: 0.8618896312040862,\n",
       " 0.47000000000000003: 0.8609499638852894,\n",
       " 0.48: 0.8610139773567249,\n",
       " 0.49: 0.8610461018851074,\n",
       " 0.5: 0.8610461018851074,\n",
       " 0.51: 0.8610783064969952,\n",
       " 0.52: 0.8610783064969952,\n",
       " 0.53: 0.8611105923863331,\n",
       " 0.54: 0.8611105923863331,\n",
       " 0.55: 0.8611105923863331,\n",
       " 0.56: 0.8611105923863331,\n",
       " 0.5700000000000001: 0.8611105923863331,\n",
       " 0.58: 0.8611105923863331,\n",
       " 0.59: 0.8606000416319272,\n",
       " 0.6: 0.8600805106375635,\n",
       " 0.61: 0.8595260978122821,\n",
       " 0.62: 0.8595260978122821,\n",
       " 0.63: 0.8595260978122821,\n",
       " 0.64: 0.8595260978122821,\n",
       " 0.65: 0.8595260978122821,\n",
       " 0.66: 0.8595260978122821,\n",
       " 0.67: 0.8595260978122821,\n",
       " 0.68: 0.8595260978122821,\n",
       " 0.6900000000000001: 0.8595260978122821,\n",
       " 0.7000000000000001: 0.8595260978122821,\n",
       " 0.71: 0.8595260978122821,\n",
       " 0.72: 0.8595260978122821,\n",
       " 0.73: 0.8589669529650303,\n",
       " 0.74: 0.8589669529650303,\n",
       " 0.75: 0.8589669529650303,\n",
       " 0.76: 0.8589669529650303,\n",
       " 0.77: 0.8589669529650303,\n",
       " 0.78: 0.8589669529650303,\n",
       " 0.79: 0.8589669529650303,\n",
       " 0.8: 0.8589669529650303,\n",
       " 0.81: 0.8589669529650303,\n",
       " 0.8200000000000001: 0.8589669529650303,\n",
       " 0.8300000000000001: 0.8589669529650303,\n",
       " 0.84: 0.8589669529650303,\n",
       " 0.85: 0.8589669529650303,\n",
       " 0.86: 0.8589669529650303,\n",
       " 0.87: 0.8589669529650303,\n",
       " 0.88: 0.8589669529650303,\n",
       " 0.89: 0.8589669529650303,\n",
       " 0.9: 0.8589669529650303,\n",
       " 0.91: 0.8589669529650303,\n",
       " 0.92: 0.8589669529650303,\n",
       " 0.93: 0.8589669529650303,\n",
       " 0.9400000000000001: 0.8589669529650303,\n",
       " 0.9500000000000001: 0.8589669529650303,\n",
       " 0.96: 0.8589669529650303,\n",
       " 0.97: 0.8589669529650303,\n",
       " 0.98: 0.8589669529650303,\n",
       " 0.99: 0.8589669529650303,\n",
       " 1.0: 0.8589669529650303}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seuil_fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693541715013169"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('D:\\Documents\\OpenClassrooms\\P7_delfosse_emilie\\model_pkl2', 'wb') as files:\n",
    "    pickle.dump(clf_opt, files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1dc7c189b7b81a002ba740c61ae7e4e6b4e604349897014f2afb63a5ad05c141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
